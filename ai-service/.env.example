# ── Muraho Rwanda AI Service — Environment Variables ──────

# Service
DEBUG=false
LOG_LEVEL=INFO

# Network (internal only — AI service is NOT exposed to internet)
ALLOWED_ORIGINS=["http://localhost:3000","http://app-server:3000"]
APP_SERVER_URL=http://app-server:3000

# LLM Backend: "ollama" (dev) or "vllm" (production)
LLM_BACKEND=ollama
LLM_BASE_URL=http://localhost:11434/v1

# Models (must match what's loaded in Ollama/vLLM)
LLM_MODEL_FAST=mistral
LLM_MODEL_HEAVY=mixtral
LLM_MODEL_DEFAULT=mistral

# Generation
LLM_MAX_TOKENS=1024
LLM_TEMPERATURE=0.3
LLM_TEMPERATURE_CREATIVE=0.7

# Embeddings (runs on CPU)
EMBEDDING_MODEL=intfloat/multilingual-e5-large
EMBEDDING_DIMENSION=1024
EMBEDDING_DEVICE=cpu

# PostgreSQL + pgvector
DATABASE_URL=postgresql://muraho:muraho_secure_password@localhost:5432/muraho

# Whisper (runs on GPU)
WHISPER_MODEL=large-v3
WHISPER_DEVICE=cuda
WHISPER_COMPUTE_TYPE=float16

# Translation
TRANSLATION_MODEL=facebook/nllb-200-distilled-600M

# Safety
ENABLE_AUDIT_LOG=true
AUDIT_LOG_PATH=/var/log/muraho/ai_audit.jsonl

# Redis
REDIS_URL=redis://localhost:6379/0

# Rate Limits (queries per day)
RATE_LIMIT_FREE=5
RATE_LIMIT_PAID=100
RATE_LIMIT_AGENCY=500
